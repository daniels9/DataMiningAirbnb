{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Airbnb Prices for Munich"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of our data mining project is to predict prices for new Airbnb listings in Munich. To achieve this, we will train a regression model on existing Airbnb data from www.insideairbnb.com."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "##### [1 Preprocessing](#preprocessing)\n",
    "##### [2 Data Mining](#data_mining)\n",
    "##### [3 Interpretation and Evaluation](#interpretation_evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='preprocessing'></a>\n",
    "## 1 Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-21 21:28:23 : Dataset loaded and preprocessed.\n"
     ]
    }
   ],
   "source": [
    "%run modules/preprocessing.py\n",
    "%run modules/evaluation.py\n",
    "preprocessed_df = load_and_preprocess_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2]\n"
     ]
    }
   ],
   "source": [
    "print(preprocessed_df['minimum_nights'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accommodates   beds   0.7060608155629018\n",
      "bedrooms   beds   0.6501529074983061\n",
      "beds   accommodates   0.7060608155629018\n",
      "beds   bedrooms   0.6501529074983061\n",
      "require_guest_profile_picture   require_guest_phone_verification   0.7871857495927765\n",
      "require_guest_phone_verification   require_guest_profile_picture   0.7871857495927765\n",
      "verification_government_id   verification_jumio   0.9765520138913213\n",
      "verification_jumio   verification_government_id   0.9765520138913213\n",
      "verification_offline_government_id   verification_selfie   0.6336336790497336\n",
      "verification_selfie   verification_offline_government_id   0.6336336790497336\n"
     ]
    }
   ],
   "source": [
    "corr_matrix = preprocessed_df.corr()\n",
    "for (column_name, column_data) in corr_matrix.iteritems():\n",
    "    for row_name, value in column_data.iteritems():\n",
    "        if(value > 0.6 and column_name != row_name):\n",
    "            print(column_name, \" \", row_name, \" \", value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "k should be >=0, <= n_features = 45; got 47. Use k='all' to return all features.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-88-b1dd4273bcda>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'run'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'modules/preprocessing.py'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselect_best_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreprocessed_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_of_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m47\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Total number of features: 47\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocessed_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'maximum_price'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\data-mining-airbnb\\modules\\preprocessing.py\u001b[0m in \u001b[0;36mselect_best_features\u001b[1;34m(df, number_of_features)\u001b[0m\n\u001b[0;32m     97\u001b[0m     \u001b[1;31m# Select k best features using SelectKBest (k = 5)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[0mbest_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSelectKBest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore_func\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mchi2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnumber_of_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m     \u001b[0mfit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbest_features\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m     \u001b[0mdfscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscores_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m     \u001b[0mdfcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    346\u001b[0m                             % (self.score_func, type(self.score_func)))\n\u001b[0;32m    347\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 348\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    349\u001b[0m         \u001b[0mscore_func_ret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    350\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore_func_ret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py\u001b[0m in \u001b[0;36m_check_params\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    512\u001b[0m             raise ValueError(\"k should be >=0, <= n_features = %d; got %r. \"\n\u001b[0;32m    513\u001b[0m                              \u001b[1;34m\"Use k='all' to return all features.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 514\u001b[1;33m                              % (X.shape[1], self.k))\n\u001b[0m\u001b[0;32m    515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_support_mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: k should be >=0, <= n_features = 45; got 47. Use k='all' to return all features."
     ]
    }
   ],
   "source": [
    "%run modules/preprocessing.py\n",
    "features = select_best_features(preprocessed_df, number_of_features = 47) # Total number of features: 47\n",
    "label = preprocessed_df['maximum_price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want to delete outliers, execute this after the train-test-split:\n",
    "\n",
    "# %run modules/preprocessing.py\n",
    "# x_train, y_train = delete_price_outliers(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='data_mining'></a>\n",
    "## 2 Data Mining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Baseline Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of Dummy Regressor: 143.85943496805479\n"
     ]
    }
   ],
   "source": [
    "%run modules/evaluation.py\n",
    "baseline_prediction(features, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Evaluation of different Regression Approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features:  16    maximum_nights\n",
      "Name: Specs, dtype: object\n",
      "Best Model: {'estimator': MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "             learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "             n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "             random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
      "             validation_fraction=0.1, verbose=False, warm_start=False)}\n",
      "RMSE: 133.0154338203911\n",
      "R^2: -0.006317069604503622\n",
      "Selected Features:  16      maximum_nights\n",
      "13    security_deposit\n",
      "Name: Specs, dtype: object\n",
      "Best Model: {'estimator': MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "             learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "             n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "             random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
      "             validation_fraction=0.1, verbose=False, warm_start=False)}\n",
      "RMSE: 131.41429831075507\n",
      "R^2: 0.017763632401042617\n",
      "Selected Features:  16      maximum_nights\n",
      "13    security_deposit\n",
      "14        cleaning_fee\n",
      "Name: Specs, dtype: object\n",
      "Best Model: {'estimator': MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "             learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "             n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "             random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
      "             validation_fraction=0.1, verbose=False, warm_start=False)}\n",
      "RMSE: 124.97736958329806\n",
      "R^2: 0.11163072729850676\n",
      "Selected Features:  16      maximum_nights\n",
      "13    security_deposit\n",
      "14        cleaning_fee\n",
      "15      minimum_nights\n",
      "Name: Specs, dtype: object\n",
      "Best Model: {'estimator': MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "             learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "             n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "             random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
      "             validation_fraction=0.1, verbose=False, warm_start=False)}\n",
      "RMSE: 123.82803331857055\n",
      "R^2: 0.12789511379795504\n",
      "Selected Features:  16               maximum_nights\n",
      "13             security_deposit\n",
      "14                 cleaning_fee\n",
      "15               minimum_nights\n",
      "1     host_total_listings_count\n",
      "Name: Specs, dtype: object\n",
      "Best Model: {'estimator': Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "      normalize=False, random_state=None, solver='auto', tol=0.001)}\n",
      "RMSE: 124.32057583571722\n",
      "R^2: 0.12094348874143923\n",
      "Selected Features:  16               maximum_nights\n",
      "13             security_deposit\n",
      "14                 cleaning_fee\n",
      "15               minimum_nights\n",
      "1     host_total_listings_count\n",
      "11                         beds\n",
      "Name: Specs, dtype: object\n",
      "Best Model: {'estimator': Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "      normalize=False, random_state=None, solver='auto', tol=0.001)}\n",
      "RMSE: 115.215226413346\n",
      "R^2: 0.2449937891242041\n",
      "Selected Features:  16               maximum_nights\n",
      "13             security_deposit\n",
      "14                 cleaning_fee\n",
      "15               minimum_nights\n",
      "1     host_total_listings_count\n",
      "11                         beds\n",
      "8                  accommodates\n",
      "Name: Specs, dtype: object\n",
      "Best Model: {'estimator': Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "      normalize=False, random_state=None, solver='auto', tol=0.001)}\n",
      "RMSE: 105.09594007023117\n",
      "R^2: 0.37179317910277665\n",
      "Selected Features:  16               maximum_nights\n",
      "13             security_deposit\n",
      "14                 cleaning_fee\n",
      "15               minimum_nights\n",
      "1     host_total_listings_count\n",
      "11                         beds\n",
      "8                  accommodates\n",
      "21               maximum_people\n",
      "Name: Specs, dtype: object\n",
      "Best Model: {'estimator': Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "      normalize=False, random_state=None, solver='auto', tol=0.001)}\n",
      "RMSE: 105.08200307556089\n",
      "R^2: 0.37195978372286764\n",
      "Selected Features:  16               maximum_nights\n",
      "13             security_deposit\n",
      "14                 cleaning_fee\n",
      "15               minimum_nights\n",
      "1     host_total_listings_count\n",
      "11                         beds\n",
      "8                  accommodates\n",
      "21               maximum_people\n",
      "4        neighbourhood_cleansed\n",
      "Name: Specs, dtype: object\n",
      "Best Model: {'estimator': Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "      normalize=False, random_state=None, solver='auto', tol=0.001)}\n",
      "RMSE: 105.04073992278451\n",
      "R^2: 0.3724529191895627\n",
      "Selected Features:  16               maximum_nights\n",
      "13             security_deposit\n",
      "14                 cleaning_fee\n",
      "15               minimum_nights\n",
      "1     host_total_listings_count\n",
      "11                         beds\n",
      "8                  accommodates\n",
      "21               maximum_people\n",
      "4        neighbourhood_cleansed\n",
      "10                     bedrooms\n",
      "Name: Specs, dtype: object\n",
      "Best Model: {'estimator': Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "      normalize=False, random_state=None, solver='auto', tol=0.001)}\n",
      "RMSE: 105.32367330309147\n",
      "R^2: 0.3690676965973779\n",
      "Selected Features:  16               maximum_nights\n",
      "13             security_deposit\n",
      "14                 cleaning_fee\n",
      "15               minimum_nights\n",
      "1     host_total_listings_count\n",
      "11                         beds\n",
      "8                  accommodates\n",
      "21               maximum_people\n",
      "4        neighbourhood_cleansed\n",
      "10                     bedrooms\n",
      "7                     room_type\n",
      "Name: Specs, dtype: object\n",
      "Best Model: {'estimator': Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "      normalize=False, random_state=None, solver='auto', tol=0.001)}\n",
      "RMSE: 105.29434930414072\n",
      "R^2: 0.369418973419653\n",
      "Selected Features:  16               maximum_nights\n",
      "13             security_deposit\n",
      "14                 cleaning_fee\n",
      "15               minimum_nights\n",
      "1     host_total_listings_count\n",
      "11                         beds\n",
      "8                  accommodates\n",
      "21               maximum_people\n",
      "4        neighbourhood_cleansed\n",
      "10                     bedrooms\n",
      "7                     room_type\n",
      "30             24-hour check-in\n",
      "Name: Specs, dtype: object\n",
      "Best Model: {'estimator': Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "      normalize=False, random_state=None, solver='auto', tol=0.001)}\n",
      "RMSE: 105.2545483421117\n",
      "R^2: 0.36989559895987856\n",
      "Selected Features:  16               maximum_nights\n",
      "13             security_deposit\n",
      "14                 cleaning_fee\n",
      "15               minimum_nights\n",
      "1     host_total_listings_count\n",
      "11                         beds\n",
      "8                  accommodates\n",
      "21               maximum_people\n",
      "4        neighbourhood_cleansed\n",
      "10                     bedrooms\n",
      "7                     room_type\n",
      "30             24-hour check-in\n",
      "46              distance_centre\n",
      "Name: Specs, dtype: object\n",
      "Best Model: {'estimator': Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "      normalize=False, random_state=None, solver='auto', tol=0.001)}\n",
      "RMSE: 104.73014216836174\n",
      "R^2: 0.37615865355489975\n",
      "Selected Features:  16                      maximum_nights\n",
      "13                    security_deposit\n",
      "14                        cleaning_fee\n",
      "15                      minimum_nights\n",
      "1            host_total_listings_count\n",
      "11                                beds\n",
      "8                         accommodates\n",
      "21                      maximum_people\n",
      "4               neighbourhood_cleansed\n",
      "10                            bedrooms\n",
      "7                            room_type\n",
      "30                    24-hour check-in\n",
      "46                     distance_centre\n",
      "20    require_guest_phone_verification\n",
      "Name: Specs, dtype: object\n",
      "Best Model: {'estimator': Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "      normalize=False, random_state=None, solver='auto', tol=0.001)}\n",
      "RMSE: 104.6798094646959\n",
      "R^2: 0.376758138588271\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "import itertools\n",
    "from math import sqrt\n",
    "\n",
    "estimators = [ LinearRegression(), Ridge(), KNeighborsRegressor(), DecisionTreeRegressor(), MLPRegressor(), SVR() ]\n",
    "pipeline = Pipeline([ ('preprocessing', StandardScaler()), ('estimator', None) ])\n",
    "parameters = {\n",
    "    'estimator': estimators\n",
    "}\n",
    "search = GridSearchCV(pipeline, parameters, cv=10, scoring='neg_mean_squared_error')\n",
    "\n",
    "for i in range(1, 15):\n",
    "    features = select_best_features(preprocessed_df, number_of_features = i)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(features, label, test_size = 0.2, random_state = 0)\n",
    "    search.fit(x_train, y_train)\n",
    "    \n",
    "    predictions = search.predict(x_test)\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "\n",
    "    print(\"Best Model: {}\".format(search.best_params_))\n",
    "    print(\"RMSE: {}\".format(sqrt(mse)))\n",
    "    print(\"R^2: {}\".format(r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model: {'estimator': MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "             learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "             n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "             random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
      "             validation_fraction=0.1, verbose=False, warm_start=False)}\n",
      "RMSE: 142.5537543342086\n",
      "R^2: 0.2519363931631057\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "import itertools\n",
    "from math import sqrt\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, label, test_size = 0.2, random_state = 0)\n",
    "\n",
    "x_train, y_train = delete_price_outliers(x_train, y_train)\n",
    "\n",
    "# test different regression approaches\n",
    "estimators = [ LinearRegression(), Ridge(), KNeighborsRegressor(), DecisionTreeRegressor(), MLPRegressor(), SVR() ]\n",
    "svr = [ SVR() ]\n",
    "pipeline = Pipeline( [ ('preprocessing', StandardScaler()), ('estimator', None) ])\n",
    "\n",
    "# define a parameter grid\n",
    "parameters = {\n",
    "    'estimator': estimators\n",
    "}\n",
    "\n",
    "# define and run a grid search using MSE as scoring metric\n",
    "search = GridSearchCV(pipeline, parameters, cv=10, scoring='neg_mean_squared_error')\n",
    "search.fit(x_train, y_train)\n",
    "\n",
    "# evaluate on test set\n",
    "predictions = search.predict(x_test)\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "r2 = r2_score(y_test, predictions)\n",
    "\n",
    "print(\"Best Model: {}\".format(search.best_params_))\n",
    "print(\"RMSE: {}\".format(sqrt(mse)))\n",
    "print(\"R^2: {}\".format(r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Evaluation of the Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               feature      F value  p_value\n",
      "21                            internet     0.075386   0.7837\n",
      "20    require_guest_phone_verification     0.124135   0.7246\n",
      "19       require_guest_profile_picture     0.371246   0.5423\n",
      "27                           breakfast     0.801910   0.3705\n",
      "35                  verification_phone     0.901576   0.3424\n",
      "3               host_identity_verified     1.099106   0.2945\n",
      "2                 host_has_profile_pic     1.157993   0.2819\n",
      "29                    24-hour check-in     1.366989   0.2424\n",
      "32                     smoking allowed     1.476614   0.2243\n",
      "25                              washer     1.494722   0.2215\n",
      "38                  verification_jumio     1.638808   0.2005\n",
      "34                  verification_email     1.851011   0.1737\n",
      "33                host_lives_in_munich     2.178843   0.1400\n",
      "43                 verification_google     2.440783   0.1183\n",
      "37          verification_government_id     2.809352   0.0938\n",
      "42             verification_work_email     3.214182   0.0730\n",
      "5                    is_location_exact     3.421043   0.0644\n",
      "16                      maximum_nights     3.641194   0.0564\n",
      "24                             heating     3.800290   0.0513\n",
      "1            host_total_listings_count     4.517535   0.0336\n",
      "41                 verification_selfie     6.000310   0.0143\n",
      "36                verification_reviews     9.785378   0.0018\n",
      "26                    patio or balcony     9.854159   0.0017\n",
      "39  verification_offline_government_id    10.012162   0.0016\n",
      "4               neighbourhood_cleansed     9.914056   0.0016\n",
      "40               verification_facebook    11.555059   0.0007\n",
      "0                    host_is_superhost    11.596921   0.0007\n",
      "28                            elevator    13.387418   0.0003\n",
      "23                             kitchen    16.433805   0.0001\n",
      "31                          dishwasher    37.879996   0.0000\n",
      "22                                  tv    62.762084   0.0000\n",
      "30                    private entrance    27.070655   0.0000\n",
      "18                 cancellation_policy   175.422037   0.0000\n",
      "17                    instant_bookable    19.824182   0.0000\n",
      "15                      minimum_nights    49.913775   0.0000\n",
      "14                        cleaning_fee   403.621567   0.0000\n",
      "13                    security_deposit   131.389261   0.0000\n",
      "12                            bed_type    20.602411   0.0000\n",
      "11                                beds  1609.725979   0.0000\n",
      "10                            bedrooms  1115.803013   0.0000\n",
      "9                            bathrooms   141.595013   0.0000\n",
      "8                         accommodates  3568.830126   0.0000\n",
      "7                            room_type   350.230801   0.0000\n",
      "6                        property_type    22.191534   0.0000\n",
      "44                     distance_centre    70.660847   0.0000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "import itertools\n",
    "from math import sqrt\n",
    "\n",
    "%run modules/preprocessing.py\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(preprocessed_df.drop(['maximum_price'], 1), label, test_size = 0.2, random_state = 0)\n",
    "tmp = select_best_features_f(x_train, y_train, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse:  128.45771016278348\n"
     ]
    }
   ],
   "source": [
    "%run modules/evaluation.py\n",
    "%run modules/preprocessing.py\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "best_r2 = 0\n",
    "\n",
    "# k-fold cross-validation (k = 10)\n",
    "scores = []\n",
    "k_fold_cross_validation = KFold(10, True, 1)\n",
    "for train_index, test_index in k_fold_cross_validation.split(tmp_features):\n",
    "\n",
    "    # Split the dataset for training and testing\n",
    "    x_train, x_test, y_train, y_test = tmp_features.loc[train_index, :], tmp_features.loc[test_index, :], label[train_index], label[test_index]\n",
    "\n",
    "    # Support Vector Regressor (SVR) using training dataset\n",
    "    svr = SVR(C=0.7, cache_size=200, coef0=0.0, degree=3, epsilon=0.7,\n",
    "    gamma='auto_deprecated', kernel='rbf', max_iter=-1, shrinking=True,\n",
    "    tol=0.001, verbose=False)\n",
    "    svr.fit(x_train, y_train)\n",
    "\n",
    "    # Evaluation using testing dataset\n",
    "    predictions = svr.predict(x_test)\n",
    "    scores.append(sqrt(mean_squared_error(y_test, predictions)))  \n",
    "\n",
    "# Calculate performance measures\n",
    "print(\"rmse: \", str(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "import itertools\n",
    "from math import sqrt\n",
    "\n",
    "estimators = [ LinearRegression(), Ridge(), KNeighborsRegressor(), DecisionTreeRegressor(), MLPRegressor(), SVR() ]\n",
    "pipeline = Pipeline([ ('preprocessing', StandardScaler()), ('estimator', None) ])\n",
    "parameters = {\n",
    "    'estimator': estimators\n",
    "}\n",
    "search = GridSearchCV(pipeline, parameters, cv=10, scoring='neg_mean_squared_error')\n",
    "\n",
    "for i in range(1, 15):\n",
    "    features = select_best_features(preprocessed_df, number_of_features = i)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(features, label, test_size = 0.2, random_state = 0)\n",
    "    search.fit(x_train, y_train)\n",
    "    \n",
    "    predictions = search.predict(x_test)\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "\n",
    "    print(\"Best Model: {}\".format(search.best_params_))\n",
    "    print(\"RMSE: {}\".format(sqrt(mse)))\n",
    "    print(\"R^2: {}\".format(r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-eaec066aa179>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;31m# Support Vector Regressor (SVR) using training dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0msvr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSVR\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'linear'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0msvr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;31m# Evaluation using testing dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m         \u001b[0mseed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'i'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m         \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m         \u001b[1;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[1;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[0;32m    266\u001b[0m                 \u001b[0mcache_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m                 \u001b[0mgamma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 268\u001b[1;33m                 max_iter=self.max_iter, random_seed=random_seed)\n\u001b[0m\u001b[0;32m    269\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_warn_from_fit_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%run modules/evaluation.py\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "best_r2 = 0\n",
    "\n",
    "tmp_features = preprocessed_df[['accommodates', 'host_is_superhost', 'distance_centre']]\n",
    "\n",
    "# k-fold cross-validation (k = 10)\n",
    "scores = []\n",
    "k_fold_cross_validation = KFold(10, True, 1)\n",
    "for train_index, test_index in k_fold_cross_validation.split(tmp_features):\n",
    "\n",
    "    # Split the dataset for training and testing\n",
    "    x_train, x_test, y_train, y_test = tmp_features.loc[train_index, :], tmp_features.loc[test_index, :], label[train_index], label[test_index]\n",
    "\n",
    "    # Support Vector Regressor (SVR) using training dataset\n",
    "    svr = SVR(kernel='linear', C = 0.7)\n",
    "    svr.fit(x_train, y_train)\n",
    "\n",
    "    # Evaluation using testing dataset\n",
    "    scores.append(svr.score(x_test, y_test))  \n",
    "\n",
    "# Calculate performance measures\n",
    "print(\"r2: \", str(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-71bd6feefa3e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;31m# Support Vector Regressor (SVR) using training dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0msvr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSVR\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'linear'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0msvr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[1;31m# Evaluation using testing dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    144\u001b[0m         X, y = check_X_y(X, y, dtype=np.float64,\n\u001b[0;32m    145\u001b[0m                          \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'C'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 146\u001b[1;33m                          accept_large_sparse=False)\n\u001b[0m\u001b[0;32m    147\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    717\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 719\u001b[1;33m                     estimator=estimator)\n\u001b[0m\u001b[0;32m    720\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    541\u001b[0m             _assert_all_finite(array,\n\u001b[1;32m--> 542\u001b[1;33m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[0;32m    543\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan)\u001b[0m\n\u001b[0;32m     54\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[0;32m     55\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'infinity'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'NaN, infinity'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype_err\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m     \u001b[1;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'object'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "%run modules/evaluation.py\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "best_r2 = 0\n",
    "\n",
    "# Generate all feature combinations\n",
    "feature_combinations = generate_feature_combinations(already_preprocessed)\n",
    "\n",
    "for feature_combination in feature_combinations:\n",
    "    \n",
    "    # Filter the selected features\n",
    "    selected_features = already_preprocessed[feature_combination]\n",
    "    \n",
    "    # k-fold cross-validation (k = 10)\n",
    "    scores = []\n",
    "    k_fold_cross_validation = KFold(10, True, 1)\n",
    "    for train_index, test_index in k_fold_cross_validation.split(selected_features):\n",
    "    \n",
    "        # Split the dataset for training and testing\n",
    "        x_train, x_test, y_train, y_test = selected_features.loc[train_index, :], selected_features.loc[test_index, :], label[train_index], label[test_index]\n",
    "\n",
    "        # Support Vector Regressor (SVR) using training dataset\n",
    "        svr = SVR(kernel='linear', C = 0.7)\n",
    "        svr.fit(x_train, y_train)\n",
    "\n",
    "        # Evaluation using testing dataset\n",
    "        scores.append(svr.score(x_test, y_test))  \n",
    "\n",
    "    # Calculate performance measures\n",
    "    print(np.mean(scores), \" - \", feature_combination)\n",
    "\n",
    "    # Save best model\n",
    "    if(np.mean(scores) > best_r2):\n",
    "          best_r2 = np.mean(scores)\n",
    "        \n",
    "print(\"Best: \", best_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Evaluation of Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='interpretation_evaluation'></a>\n",
    "## 3 Interpretation and Evaluation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
